{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bab4a1de",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading...: 100%|██████████| 909/909 [00:34<00:00, 26.14it/s]\n"
     ]
    }
   ],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from tqdm import tqdm\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "\n",
    "df7 = spark.read.csv('/home/jovyan/data/transaction.csv', sep='|', header=True, inferSchema=True)\n",
    "\n",
    "df7.createOrReplaceTempView('table1')\n",
    "\n",
    "df5=spark.sql(\"\"\"\n",
    "with table03 as(\n",
    "with table02 as(\n",
    "with table01 as (\n",
    "select custId\n",
    "        ,cast(transactionDate as date) DateCast\n",
    "        ,row_number() over(partition by custId order by custId\n",
    "        ,transactionDate) rn\n",
    "from table1 \n",
    "group by custId,transactionDate\n",
    "order by custId,transactionDate)\n",
    "select *\n",
    "        ,date_add(DateCast,-rn) as grp\n",
    "from table01 )\n",
    "select custId,grp,min(DateCast),max(DateCast),datediff(max(DateCast),min(DateCast))+1 as consecutive\n",
    "from table02\n",
    "group by custId,grp)\n",
    "select custId,max(consecutive) consecutive_\n",
    "from table03\n",
    "group by custId\n",
    "\n",
    "\n",
    "\"\"\")\n",
    "df5.createOrReplaceTempView('table5')\n",
    "\n",
    "df2=spark.sql(\"\"\"\n",
    "\n",
    "\n",
    "select custId,productSold,sum(unitsSold) sum_\n",
    "from table1 t1\n",
    "group by custId,productSold\n",
    "order by custId,sum_ desc\n",
    "\n",
    "\n",
    "\"\"\")\n",
    "df2.createOrReplaceTempView('table2')\n",
    "\n",
    "df3=spark.sql(\"\"\"\n",
    "\n",
    "with table01 as(\n",
    "select custId,productSold,sum(unitsSold) sum_\n",
    "from table1 t1\n",
    "group by custId,productSold\n",
    "order by custId,sum_ desc)\n",
    "select custId,max(sum_) as fav\n",
    "from table01\n",
    "group by custId\n",
    "\n",
    "\n",
    "\n",
    "\"\"\")\n",
    "df3.createOrReplaceTempView('table3')\n",
    "\n",
    "df4=spark.sql(\"\"\"\n",
    "\n",
    "select t2.custId,t2.productSold\n",
    "from table2 t2\n",
    "join table3 t3\n",
    "on t2.custId = t3.custId and t2.sum_ = t3.fav\n",
    "\n",
    "\"\"\")\n",
    "df4.createOrReplaceTempView('table4')\n",
    "\n",
    "df=spark.sql(\"\"\"\n",
    "\n",
    "select t4.custId as customer_id,t4.productSold as favourite_product,t5.consecutive_ as longest_streak\n",
    "from table4 t4\n",
    "join table5 t5\n",
    "on t4.custId = t5.custId\n",
    "\n",
    "\"\"\")\n",
    "\n",
    "from sqlalchemy import create_engine\n",
    "from datetime import datetime\n",
    "\n",
    "conn_str = \"postgresql+psycopg2://root:password@postgres_db:5432/bookstore\"\n",
    "\n",
    "engine = create_engine(conn_str)\n",
    "connection = engine.connect()\n",
    "\n",
    "# res = connection.execute(\"CREATE TABLE IF NOT EXISTS champ (id serial PRIMARY KEY, num integer, data varchar);\")\n",
    "\n",
    "\n",
    "# res = connection.execute(\"\"\"SELECT *\n",
    "# FROM pg_catalog.pg_tables\n",
    "# WHERE schemaname != 'pg_catalog' AND \n",
    "#     schemaname != 'information_schema';\"\"\")\n",
    "\n",
    "# res.fetchall()\n",
    "\n",
    "# df.show()\n",
    "\n",
    "# df.schema.jsonValue()['fields']\n",
    "\n",
    "dict_ConvertType={'string':'varchar'}\n",
    "\n",
    "stm = ''\n",
    "for i_,i in enumerate(df.schema.jsonValue()['fields']):\n",
    "    if i['type'] in dict_ConvertType.keys():\n",
    "        i['type'] = dict_ConvertType[i['type']]\n",
    "    if i_ == 0:\n",
    "        #print(i['name']+' '+i['type'])\n",
    "        stm += i['name']+' '+i['type']\n",
    "    else:\n",
    "        #print(','+i['name']+' '+i['type'])\n",
    "        stm += ', '+i['name']+' '+i['type']\n",
    "\n",
    "\n",
    "stm\n",
    "\n",
    "table_name = 'customers'\n",
    "create_table_stm = 'CREATE TABLE IF NOT EXISTS {0} ({1});'.format(table_name,stm)\n",
    "\n",
    "create_table_stm\n",
    "\n",
    "res = connection.execute(create_table_stm)\n",
    "\n",
    "res = connection.execute(\"\"\"SELECT *\n",
    "FROM pg_catalog.pg_tables\n",
    "WHERE schemaname != 'pg_catalog' AND \n",
    "    schemaname != 'information_schema';\"\"\")\n",
    "\n",
    "res.fetchall()\n",
    "\n",
    "res = connection.execute(\"TRUNCATE TABLE  {}\".format(table_name))\n",
    "\n",
    "for i in tqdm (range(0,len(df.collect())), desc=\"Loading...\"):\n",
    "    #print(df.collect()[i][:])\n",
    "    value_stm = 'INSERT INTO {} VALUES {}'.format(table_name,df.collect()[i][:])\n",
    "    #print(value_stm)\n",
    "    res = connection.execute(value_stm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c6071275",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄\n",
      "██░▄▄▄░██░▄▄▄██░▄▄▀█▄▄░▄▄█▄░▄██░▄▄▄░\n",
      "██▄▄▄▀▀██░▄▄▄██░▀▀▄███░████░███▄▄▄▀▀\n",
      "██░▀▀▀░██░▀▀▀██░██░███░███▀░▀██░▀▀▀░\n",
      "▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀\n",
      "                    \n"
     ]
    }
   ],
   "source": [
    "print(\"\"\"\\\n",
    "\n",
    "▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄\n",
    "██░▄▄▄░██░▄▄▄██░▄▄▀█▄▄░▄▄█▄░▄██░▄▄▄░\n",
    "██▄▄▄▀▀██░▄▄▄██░▀▀▄███░████░███▄▄▄▀▀\n",
    "██░▀▀▀░██░▀▀▀██░██░███░███▀░▀██░▀▀▀░\n",
    "▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀\n",
    "                    \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fdccec5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
